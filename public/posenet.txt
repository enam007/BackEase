import { useRef, useEffect, useState } from "react";
import * as tf from "@tensorflow/tfjs";
import * as posenet from "@tensorflow-models/posenet";
import Webcam from "react-webcam";
import { drawKeypoints, drawSkeleton } from "../Utils/draw";
const PoseEstimation = () => {
  const webcamRef = useRef(null);
  const canvasRef = useRef(null);
  const [pose, setPose] = useState(null);

  useEffect(() => {
    const runPosenet = async () => {
      // const net = await posenet.load({
      //   inputResolution: { width: 640, height: 480 },
      //   scale: 0.8,
      // });
      const detectorConfig = {
        architecture: "ResNet50",
        outputStride: 32,
        inputResolution: { width: 257, height: 200 },
        quantBytes: 2,
      };
      const detector = await poseDetection.createDetector(
        poseDetection.SupportedModels.PoseNet,
        detectorConfig
      );

      if (
        typeof webcamRef.current !== "undefined" &&
        webcamRef.current !== null &&
        webcamRef.current.video.readyState === 4
      ) {
        const video = webcamRef.current.video;
        const videoWidth = webcamRef.current.video.videoWidth;
        const videoHeight = webcamRef.current.video.videoHeight;
        webcamRef.current.video.width = videoWidth;
        webcamRef.current.video.height = videoHeight;
        console.log(videoWidth);
        console.log(videoHeight);

        const detect = async () => {
          const Detectedpose = await net.estimateSinglePose(video);
          setPose(Detectedpose);
          drawPose(Detectedpose, video, videoWidth, videoHeight);

          requestAnimationFrame(detect);
        };
        detect();
      }
    };
    runPosenet();
  }, []);

  const drawPose = (pose, video, videoWidth, videoHeight) => {
    console.log(pose);
    if (canvasRef.current && pose && pose.keypoints) {
      const ctx = canvasRef.current.getContext("2d");
      canvasRef.current.width = videoWidth;
      canvasRef.current.height = videoHeight;

      drawKeypoints(pose["keypoints"], 0.6, ctx);
      drawSkeleton(pose["keypoints"], 0.7, ctx);
      // ctx.save();
      // ctx.scale(-1, 1);
      //ctx.translate(-videoWidth, 0);
      //ctx.drawImage(video, 0, 0, videoWidth, videoHeight);
      //ctx.restore();

      //ctx.clearRect(0, 0, canvasRef.width, canvasRef.height);
    }
  };

  return (
    <div>
      <Webcam
        ref={webcamRef}
        className="absolute left-0 text-center z-9 w-1/2 h-full"
      />
      <canvas
        ref={canvasRef}
        className="absolute left-0 text-center z-9 w-1/2 h-full"
      />
    </div>
  );
};

export default PoseEstimation;
